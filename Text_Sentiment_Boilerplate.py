import tensorflow.keras
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

sentence = ["I am happy to meet my friends. We are planning to go a party.", 
            "I had a bad day at school. i got hurt while playing football"]

# Tokenizaci√≥n

# Crear un diccionario word_index

# Rellenar la secuencia

# Definir el modelo usando un arhivo .h5

# Probar el modelo

# Imprimir el resultado
